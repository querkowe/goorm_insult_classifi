from googleapiclient.discovery import build
from oauth2client.tools import argparser
from django.conf import settings
import pandas as pd
from datetime import datetime

from . import analysis

# ìœ íŠœë¸Œì˜ ISO 8601 í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë©´#
def date_parse(src):
    dt = datetime.fromisoformat(src[:-1])
    return dt.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ")

def get_comments(video):

    # print(video)

    #ì‚¬ìš©ì ê³„ì • api_key
    api_key = settings.API_KEY

    # ë¹„ë””ì˜¤ ì£¼ì†Œ ë§¨ ë’¤ìª½ì— ìˆìŒ
    video_id = video

    # ì˜ìƒ í•˜ë‚˜ë‹¹ ìµœëŒ€ ëŒ“ê¸€ ê°¯ìˆ˜ -> ì‹œê°„ ê´€ê³„ìƒ ì œ
    limit = 100

    comments = list()
    api_obj = settings.YOUTUBE_OBJ
    good_count = 0
    bad_count = 0
    response = api_obj.commentThreads().list(part='snippet,replies', videoId=video_id, maxResults=100).execute()

    if response and len(comments) < limit:
        for item in response['items']:
            comment = item['snippet']['topLevelComment']['snippet']

            comments.append([comment['textDisplay'], date_parse(comment['publishedAt']), comment['likeCount']])

            result = analysis.predict_sent(comments[-1][0])

            if result == 0:
                result = " ì•…ì„± ğŸ‘¿"
                bad_count += 1
            elif result == 1:
                result = " ì •ìƒ ğŸ˜€"
                good_count += 1

            comments[-1].append(result)

    return good_count, bad_count, pd.DataFrame(comments, columns=['ëŒ“ê¸€ ë‚´ìš©', 'ê²Œì‹œì¼', 'ì¢‹ì•„ìš”', 'íŒë³„ ê²°ê³¼']).to_html(classes='table table-dark', index=False).strip()


# í‚¤ì›Œë“œë¥¼ í†µí•œ ì˜ìƒ ëª©ë¡ ê²€ìƒ‰
def search_text(text):
    query_text = text
    max_results = 10
    youtube = settings.YOUTUBE_OBJ

    search_response = youtube.search().list(
        q=query_text,
        order="relevance",
        part="snippet",
        type='video',
        maxResults=max_results,
        # videoEmbeddable=true,
        regionCode="kr",
        relevanceLanguage="ko"
    ).execute()

    videos = []

    for i in range(len(search_response['items'])):

        videos.append(
            [
                search_response['items'][i]['id']['videoId'].strip(),
                search_response['items'][i]['snippet']['title'].strip(),
                search_response['items'][i]['snippet']['description'].strip(),
                search_response['items'][i]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][i]['snippet']['channelId'].strip(),
                search_response['items'][i]['snippet']['channelTitle'].strip(),
                date_parse(search_response['items'][i]['snippet']['publishedAt'].strip()),
                # search_response['items'][i]['snippet']['publishedAt'].strip(),
            ]
        )

    return videos

# í‚¤ì›Œë“œë¥¼ í†µí•œ ì±„ë„ ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰
def channel_list(text):
    query_text = text
    max_results = 10
    youtube = settings.YOUTUBE_OBJ

    search_response = youtube.search().list(
        q=query_text,
        order="relevance",
        part="snippet",
        type='channel',
        maxResults=max_results,
        # videoEmbeddable=true,
        regionCode="kr",
        relevanceLanguage="ko"
    ).execute()

    channels = []

    for i in range(len(search_response['items'])):

        channels.append(
            [
                search_response['items'][i]['snippet']['title'].strip(),
                search_response['items'][i]['snippet']['description'].strip(),
                search_response['items'][i]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][i]['snippet']['channelId'].strip(),
                # search_response['items'][i]['snippet']['channelTitle'],
                date_parse(search_response['items'][i]['snippet']['publishedAt'].strip()),
                # search_response['items'][i]['snippet']['publishedAt'].strip(),
            ]
        )

    return channels

# ì˜ìƒ id ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•œ ì˜ìƒ ì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„
def search_video_list(vids):
    max_results = 10
    youtube = settings.YOUTUBE_OBJ

    videos = []
    sum_good= 0
    sum_bad = 0

    for vid in vids:
        search_response = youtube.videos().list(
            id=vid,
            part="id,snippet,statistics",
            maxResults=max_results,
            # videoEmbeddable=true,
            # regionCode="kr",
            # relevanceLanguage="ko"
        ).execute()

        good_count, bad_count, comments_df = get_comments(search_response['items'][0]['id'])

        sum_good += good_count
        sum_bad += bad_count

        videos.append(
            [
                search_response['items'][0]['id'].strip(),
                search_response['items'][0]['snippet']['title'].strip(),
                search_response['items'][0]['snippet']['description'].strip(),
                search_response['items'][0]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][0]['snippet']['channelId'].strip(),
                search_response['items'][0]['snippet']['channelTitle'].strip(),
                date_parse(search_response['items'][0]['snippet']['publishedAt'].strip()),
                # search_response['items'][0]['snippet']['publishedAt'].strip(),
                search_response['items'][0]['statistics']['viewCount'].strip(),
                search_response['items'][0]['statistics']['likeCount'].strip(),
                search_response['items'][0]['statistics']['favoriteCount'].strip(),
                search_response['items'][0]['statistics']['commentCount'].strip(),
                good_count,
                bad_count,
                comments_df
            ]
        )

    return videos, sum_good, sum_bad

# í‚¤ì›Œë“œë¥¼ í†µí•œ ì±„ë„ ê²€ìƒ‰
def search_channel(channel):
    query_text = channel
    max_results = 10
    youtube = settings.YOUTUBE_OBJ

    search_response = youtube.search().list(
        channelId=channel,
        order="relevance",
        part="snippet",
        type='video',
        maxResults=max_results,
        # videoEmbeddable=true,
        regionCode="kr",
        relevanceLanguage="ko"
    ).execute()

    videos = []

    for i in range(len(search_response['items'])):

        videos.append(
            [
                search_response['items'][i]['id']['videoId'].strip(),
                search_response['items'][i]['snippet']['title'].strip(),
                search_response['items'][i]['snippet']['description'].strip(),
                search_response['items'][i]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][i]['snippet']['channelId'].strip(),
                search_response['items'][i]['snippet']['channelTitle'].strip(),
                date_parse(search_response['items'][i]['snippet']['publishedAt'].strip())
                # search_response['items'][i]['snippet']['publishedAt'].strip()
            ]
        )

    return videos

# ë‹¨ì¼ ì˜ìƒ ì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„
def search_video(id):
    query_text = id
    youtube = settings.YOUTUBE_OBJ

    search_response = youtube.videos().list(
        id=query_text,
        part="id,snippet,statistics",
        # videoEmbeddable=true,
        # regionCode="kr",
        # relevanceLanguage="ko"
    ).execute()

    videos = []

    for i in range(len(search_response['items'])):

        good_count, bad_count, comments_df = get_comments(search_response['items'][i]['id'])

        videos.append(
            [
                search_response['items'][i]['id'],
                search_response['items'][i]['snippet']['title'].strip(),
                search_response['items'][i]['snippet']['description'].strip(),
                search_response['items'][i]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][i]['snippet']['channelId'].strip(),
                search_response['items'][i]['snippet']['channelTitle'].strip(),
                date_parse(search_response['items'][i]['snippet']['publishedAt'].strip()),
                # search_response['items'][i]['snippet']['publishedAt'].strip(),
                search_response['items'][i]['statistics']['viewCount'].strip(),
                search_response['items'][i]['statistics']['likeCount'].strip(),
                search_response['items'][i]['statistics']['favoriteCount'].strip(),
                search_response['items'][i]['statistics']['commentCount'].strip(),
                good_count,
                bad_count,
                comments_df
            ]
        )

    return videos

# ì˜ìƒ ì •ë³´ ê²€ìƒ‰
def preview_video(id):
    query_text = id
    youtube = settings.YOUTUBE_OBJ

    search_response = youtube.videos().list(
        id=query_text,
        part="id,snippet,statistics",
        # videoEmbeddable=true,
        # regionCode="kr",
        # relevanceLanguage="ko"
    ).execute()

    videos = []

    for i in range(len(search_response['items'])):

        videos.append(
            [
                search_response['items'][i]['id'],
                search_response['items'][i]['snippet']['title'].strip(),
                search_response['items'][i]['snippet']['description'].strip(),
                search_response['items'][i]['snippet']['thumbnails']['high']['url'].strip(),
                search_response['items'][i]['snippet']['channelId'].strip(),
                search_response['items'][i]['snippet']['channelTitle'].strip(),
                date_parse(search_response['items'][i]['snippet']['publishedAt'].strip()),
                # search_response['items'][i]['snippet']['publishedAt'].strip(),
                search_response['items'][i]['statistics']['viewCount'].strip(),
                search_response['items'][i]['statistics']['likeCount'].strip(),
                search_response['items'][i]['statistics']['favoriteCount'].strip(),
                search_response['items'][i]['statistics']['commentCount'].strip(),
            ]
        )

    return videos
