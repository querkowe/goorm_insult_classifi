import torch

from django.conf import settings

def predict_sent(sent):

    model = settings.KNAVE_MODEL
    tokenizer = settings.KNAVE_TOKENIZER
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    # ì…ë ¥ëœ ë¬¸ì¥ í† í¬ë‚˜ì´ì§•
    tokenized_sent = tokenizer(
        sent,
        return_tensors="pt",
        truncation=True,
        add_special_tokens=True,
        max_length=128
    )

    # ëª¨ë¸ì´ ìœ„ì¹˜í•œ GPUë¡œ ì´ë™
    tokenized_sent.to(device)

    # ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(
            input_ids=tokenized_sent["input_ids"],
            attention_mask=tokenized_sent["attention_mask"],
            token_type_ids=tokenized_sent["token_type_ids"]
        )

    # ê²°ê³¼ return
    logits = outputs[0]

    logits = logits.detach().cpu()
    result = logits.argmax(-1)

    # if result == 0:
    #     result = " >> ì•…ì„±ëŒ“ê¸€ ğŸ‘¿"
    # elif result == 1:
    #     result = " >> ì •ìƒëŒ“ê¸€ ğŸ˜€"

    if result == 0:
        result = 0
    elif result == 1:
        result = 1

    return result
